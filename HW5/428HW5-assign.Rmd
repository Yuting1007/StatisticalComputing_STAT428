---
title: 'STAT 428: Homework 5: <br> Chapter 7: Jackknife and Bootstrap'
author: "Du, Yuting, yutingd3"
date: ""
output:
  html_document:
    theme: readable
    toc: yes
  pdf_document:
    toc: yes
params:
  solution: TRUE
  release: FALSE
---

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
library(knitr)
opts_chunk$set(echo=FALSE,
               cache=TRUE, autodep=TRUE, cache.comments=FALSE,
               message=FALSE, warning=FALSE)

grd = FALSE
```

---------------------------------------

Please refer to the [**detailed homework policy document**] on Course Page for information about homework formatting, submission, and grading. 

---------------------------------------

## Exercise 1  
**Bootstrap (Normal).**

Perform the following tasks:

  1. Generate a sample of size 100 from `N(10,1)` distribution.  
```{r, echo=TRUE, eval= TRUE}
n = 100
x = rnorm(n, 10, 1)

```
  



  2. Estimate the mean of observations in this sample.  
```{r, echo=TRUE, eval= TRUE}
m = mean(x)

```  


  
  3. Use Bootstrap to estimate the standard error of this mean.  
```{r, echo=TRUE, eval= TRUE}
B = 10000
Tboot <- numeric(B)
for (b in 1 : B) {
  xb <- sample(x, n, replace=TRUE)
  Tboot[b] <- mean(xb)
}
(se <- sd(Tboot))

```    


  
  

  4. What should be (theoretically) and is (practically according to your experiment) the relation between this Bootstrap estimate and the actual standard deviation of the distribution you sampled from?  
  
```{r, echo = TRUE,eval=TRUE}
norm_sd <- 1 / 5
(se_theory <- norm_sd / sqrt(n))
```

  
  

  5. Calculate a 95\% confidence interval for the estimate of mean (based on bootstrap).  
```{r, echo = TRUE,eval=TRUE}
zval <- qnorm(.975)
(lower <- m - zval * se)
(upper <- m + zval * se)
```  



  
  
  
## Exercise 2  
**Jackknife (Normal).**

Consider the same sample that you generated in Exercise 1.1 and the same estimator you used in Exercise 1.2. Find the jackknife estimate of the bias of this estimator. (You may choose to guess the answer instead of performing the jackknife procedure, in that case EXPLAIN clearly why your guess makes sense.)  
```{r, eval=TRUE, eval=TRUE}
jackknife_sd=function(x){
  n=length(x)
  jack_sample=numeric(n)
  for (i in 1:n){
    jack_sample[i]=sd(x[-i])
  }
  #bias
  bias_jack=(n-1)*(mean(jack_sample)-sd(x))
  se_jack=sqrt((n-1) * mean((jack_sample - mean(jack_sample))^2))
  return (c(bias_jack,se_jack))
}

x <- rnorm(1000, mean = 10, sd = 1)
v <- jackknife_sd(x)
(v)
```
The bias is about -0.0002536.  




  
  

## Exercise 3  
**Bootstrap and Jackknife Error Comparison**
Consider the following (simulated) months until various batteries of the same type burn out:
```{r,echo=TRUE}
Ex3 <- c(2.228, 2.051, 1.683, 3.285, 1.219, 2.879, 2.976, 2.112, 2.357, 2.425, 1.255, 2.562, 0.829, 2.581, 2.340, 3.043, 0.684, 1.810, 2.529, 0.700)
```

1. We want to estimate the probability that these batteries burn out in less than 2 months, so $\theta=P(X<2)$.  Calculate $\hat{\theta}$.  



  
  
2. What is the standard error and bias of your estimator?  Estimate the standard error and bias using bootstrapping.




  

3. Calculate the standard error and bias using Jackknife.    
    

  
  
4. What if you wanted to calculate the median time to burn out instead?  Estimate the median, the standard error of the median estimator, and the bias of the median estimator using a resampling method.  




  

## Exercise 4  
Consider the data stored in `cw` on the weight of 30 chicks after eating two different diets for ten days.  Chicks 1-20 had diet 1, and chicks 21-30 had diet 2.  
```{r,echo=TRUE}
cw<-ChickWeight[ChickWeight$Time==10&ChickWeight$Diet %in% c("1","2"),]
cw<-droplevels(cw)
```
Using a permutation test, determine whether the mean weights of the chicks on the two diets are different.  Clearly show your steps, with at least comments to explain what you are doing (you should be doing this anyway, but just a reminder).  What do you conclude?  





  

## Exercise 5 

Do exercise 7.3 from the book. 

7.3 Obtain a bootstrap t confidence interval estimate for the correlation statistic in Example 7.2 (law data in bootstrap).


  


## Exercise 6 

Do exercise 7.10 from the book.  

7.10 In Example 7.18, leave-one-out (n-fold) cross validation was used to select the best fitting model. Repeat the analysis replacing the Log-Log model with a cubic polynomial model. Which of the four models is selected by the cross validation procedure? Which model is selected according to maximus adjusted $R^2$?



  

## Exercise 7  
Do exercise 7.11 from the book.  

7.11 In Example 7.18, leave-one-out (n-fold) cross validation was used to select the best fitting model. Use leave-two-out cross validation to compare the models.

```{r, eval= TRUE, echo= TRUE}
library(DAAG)

attach(ironslag)
n <- length(magnetic) #in DAAG ironslag
e1 <- e2 <- e3 <- e4 <- numeric(n*(n-1)) # 'leave two out' has n(n-1) combinations
for (i in 1:n){
  for (j in i:n){
    if (i != j){
      y=magnetic[c(-i,-j)]
      x=chemical[c(-i,-j)]
      
      J1 <- lm(y ~ x)
      yhat11 <- J1$coef[1] + J1$coef[2] * chemical[i]
      yhat12 <- J1$coef[1] + J1$coef[2] * chemical[j]
      e1[(i-1)*n+j] <- sqrt((magnetic[i] - yhat11)^2+(magnetic[j] - yhat12)^2)
      
      J2 <- lm(y ~ x + I(x^2))
      yhat21 <- J2$coef[1] + J2$coef[2] * chemical[i] +
      J2$coef[3] * chemical[i]^2
      yhat22 <- J2$coef[1] + J2$coef[2] * chemical[j] +
      J2$coef[3] * chemical[j]^2
      e2[(i-1)*n+j] <- sqrt((magnetic[i] - yhat21)^2+(magnetic[j] - yhat22)^2)
      
      J3 <- lm(log(y) ~ x)
      logyhat31 <- J3$coef[1] + J3$coef[2] * chemical[i]
      logyhat32 <- J3$coef[1] + J3$coef[2] * chemical[j]
      yhat31 <- exp(logyhat31)
      yhat32 <- exp(logyhat32)
      e3[(i-1)*n+j] <- sqrt((magnetic[i] - yhat31)^2+(magnetic[j] - yhat32)^2)
      
      J4 <- lm(log(y) ~ log(x))
      logyhat41 <- J4$coef[1] + J4$coef[2] * log(chemical[i])
      logyhat42 <- J4$coef[1] + J4$coef[2] * log(chemical[j])
      yhat41 <- exp(logyhat41)
      yhat42 <- exp(logyhat42)
      e4[(i-1)*n+j] <- sqrt((magnetic[i] - yhat41)^2+(magnetic[j] - yhat42)^2)
    }
  }
}
# estimates for prediction error
c(mean(e1^2), mean(e2^2), mean(e3^2), mean(e4^2))

```
According to the estimates for prediction error,the quadratic model is best fit for data. Then itâ€™s the exponential model, then the linear model. The Log-log model is the worst.

  

## Exercise 8  
**Permutation Test for Spearman Correlation Coefficient**  
You can test for the independence of two random variable using the Spearman Correlation coefficient $r^2$ (which relies on ranks rather than the actual values of $X$ and $Y$) using the following test statistic:  
$t=r\sqrt{\frac{n-2}{1-r^2}}\sim t_{n-2}$, or the Student's t-distribution with $n-2$ degrees of freedom under the null hypothesis (that $X$ and $Y$ are independent).  Now, do exercise 8.2 in the book, using the t-statistic above.  Use the `Petal.Length`, `Petal.Width`, `Sepal.Width`, and `Sepal.Length` variables from `iris` to test your function and compare it to `cor.test`, like mentioned in 8.2.  (In other words, do pairwise tests).

8.2 Implement the bivariate Spearman rank correlation test for independence [255] as a permutation test. The Spearman rank correlation test statistic can be obtained from function `cor` with `method="spearman"`. Compare the achieved significance level of the permutation test with the p-value reported by `cor.test` on the same samples. 
  



  
